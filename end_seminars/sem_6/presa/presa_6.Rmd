---
title: |
  | Гипотезы да АБ-тесты: доля, среднее и дисперсия
date: |
  | 2018-05-24
author: |
  | Филипп
output: 
  revealjs::revealjs_presentation:
    css: left.css
    theme: simple
    highlight: pygments
    center: false
    smart: true
    transition: slide
    background_transition: slide
    reveal_options:
      fig_width: 5
      fig_height: 4
      slideNumber: true
      previewLinks: true
    self_contained: true
    reveal_plugins: []
---


```{r, echo=FALSE, include=FALSE}
library("ggplot2")

library('ggplot2')

# В этом блоке написаны несколько функций, которые рисуют красивые картинки для проверки гипотез.
# Можно не обращать на них внимание :) 

# Область, которую надо будет закрасить на графике 
limitRange <- function(fun, min, max) {
    function(x) {
        y <- fun(x)
        y[x < min  |  x > max] <- NA
        return(y)
    }
}

z_stat_picture <- function(z_stat, alpha =0.05, alternative = 'two-sided'){

      # Какие области надо закрасить (зависит от алтиернативы)
    if(alternative == 'two-sided'){
        z_crit <- qnorm(1-(alpha/2))
        dlimit_left  <- limitRange(dnorm, -Inf, -z_crit) 
        dlimit_right <- limitRange(dnorm, z_crit, Inf) 
        }
    if(alternative == 'less'){
        z_crit <- qnorm(alpha)
        dlimit_left  <- limitRange(dnorm, -Inf, z_crit)
        dlimit_right <- limitRange(dnorm, Inf, Inf)        
    }
    if(alternative == 'greater'){
        z_crit <- qnorm(1 - alpha)
        dlimit_left  <- limitRange(dnorm, -Inf, -Inf)
        dlimit_right <- limitRange(dnorm, z_crit, Inf)
        }        
      
    # Основная картинка
    p <- ggplot(data.frame(x=c(-3, 3)), aes(x = x))+
       stat_function(fun=dnorm) +  # вся функция 
       stat_function(fun=dlimit_left, geom="area",  fill="blue", alpha=0.2) +
       stat_function(fun=dlimit_right, geom="area", fill="blue", alpha=0.2) +
       geom_point(aes(x=z_stat,y=0), color="red", size=2) +
       geom_vline(xintercept = z_stat, size=0.3, linetype="dashed", color="red") +
       annotate("text", label=round(z_stat,2), x= z_stat, y=0.2, parse=T, size=4, color="darkred")
    
    # Рисуем критические точки 
    if(alternative == 'two-sided'){
       p <- p + annotate("text", label=round(z_crit,2), x=z_crit+0.1, y=-0.02, parse=T, size=4) + 
                annotate("text", label=round(-z_crit,2), x=-z_crit-0.1, y=-0.02, parse=T, size=4)
        }
    if(alternative == 'less'){
       p <- p + annotate("text", label=round(z_crit,2), x=z_crit-0.1, y=-0.02, parse=T, size=4)
        }
    if(alternative == 'greater'){
       p <- p + annotate("text", label=round(z_crit,2), x=z_crit+0.1, y=-0.02, parse=T, size=4)
        }      
    
    # Немного заключительных настроек, связанных с темой и вывод на экран 
    p + theme(
             axis.text.x = element_blank(),
             axis.text.y = element_blank(),
             axis.ticks = element_blank(),
             axis.title.x = element_blank(),
             axis.title.y = element_blank()
            )
}



# Точно такой же рисунок для t-статистики
t_stat_picture <- function(t_stat, n, alpha =0.05, alternative = 'two-sided'){
    # Опции для размеров графика
    options(repr.plot.width=6, repr.plot.height=3)
    
    # Какие области надо закрасить (зависит от алтиернативы)
    if(alternative == 'two-sided'){
        t_crit <- qt(1-(alpha/2),df=n)
        dlimit_left  <- limitRange(function(x) dt(x, df=n), -Inf, -t_crit) 
        dlimit_right <- limitRange(function(x) dt(x, df=n), t_crit, Inf) 
        }
    if(alternative == 'less'){
        t_crit <- qt(alpha,df=n)
        dlimit_left  <- limitRange(function(x) dt(x, df=n), -Inf, t_crit)
        dlimit_right <- limitRange(function(x) dt(x, df=n), Inf, Inf)        
    }
    if(alternative == 'greater'){
        t_crit <- qt(1 - alpha,df=n)
        dlimit_left  <- limitRange(function(x) dt(x, df=n), -Inf, -Inf)
        dlimit_right <- limitRange(function(x) dt(x, df=n), t_crit, Inf)
        }        
      
    # Основная картинка
    p <- ggplot(data.frame(x=c(-4, 4)), aes(x = x))+
       stat_function(fun=dt, args = list(df=n)) +  # вся функция 
       stat_function(fun=dlimit_left, geom="area",  fill="blue", alpha=0.2) +
       stat_function(fun=dlimit_right, geom="area", fill="blue", alpha=0.2) +
       geom_point(aes(x=t_stat,y=0), color="red", size=2) +
       geom_vline(xintercept = t_stat, size=0.3, linetype="dashed", color="red") +
       annotate("text", label=round(t_stat,2), x= t_stat, y=0.2, parse=T, size=4, color="darkred")
    
    # Рисуем критические точки 
    if(alternative == 'two-sided'){
       p <- p + annotate("text", label=round(t_crit,2), x=t_crit+0.1, y=-0.02, parse=T, size=4) + 
                annotate("text", label=round(-t_crit,2), x=-t_crit-0.1, y=-0.02, parse=T, size=4)
        }
    if(alternative == 'less'){
       p <- p + annotate("text", label=round(t_crit,2), x=t_crit-0.1, y=-0.02, parse=T, size=4)
        }
    if(alternative == 'greater'){
       p <- p + annotate("text", label=round(t_crit,2), x=t_crit+0.1, y=-0.02, parse=T, size=4)
        }      
    
    # Немного заключительных настроек, связанных с темой и вывод на экран 
    p <- p + theme(
             axis.text.x = element_blank(),
             axis.text.y = element_blank(),
             axis.ticks = element_blank(),
             axis.title.x = element_blank(),
             axis.title.y = element_blank()
            )
    
    return(p)
}


```


## Agenda 

- Как проверять гипотезы

- Точные и асимптотические критерии

- Гипотезы о долях  

- Гипотезы о средних

- Гипотезы о дисперсиях


## Примеры гипотез 

- В Австралии женщин дискриминируют на рынке труда!

- В Питере люди любят кофе больше, чем в москве! 

- Пауль - настоящий прорицатель! Его предсказания всегда сбываются!

- Доходности по акциям Яндекса имеют нормальное распределение! 



## Что делать с гипотезами

- Можно собирать данные и смотреть не противоречат ли им гипотезы

- Это не очень достоверно, надо быть готовым к ошибкам

- Гипотезы нельзя принмать, их не отвергают 



## Большая ложь агента $007$

- Предпочитает мартини взболтанным, но не смешанным 

- Как проверить правда это или пафос

<center>
<img src="bond.jpg" height="350"> 
</center>


## Эксперимент 

<center>
<img src="blackbond.jpg" height="350"> 
</center>

- Завязываем агенту глаза, предлагаем взболтанный и смешанный мартини

- Если больше понравился взболтанный $X_i = 1$


## Формализация гипотезы 

<br/>

$$
\begin{aligned}
H_0: & \quad \text{Джеймс бонд не различает напитки} \\
H_1: & \quad \text{Бонд различает напитки}
\end{aligned}
$$ 

<br/>

Выбока: $X_1, \ldots, X_n$. Если Бонд не различает два напитка, он берёт их наугад. Сформулируем это в терминах $X \sim Bern(p)$.

$$
\begin{aligned}
H_0: & \quad p = 0.5 \\
H_1: & \quad p \ne 0.5
\end{aligned}
$$ 

Можно выбрать одностороннюю альтернативу. Что это будет означать? 


## Формализация гипотезы

- Пусть $10$ экспериментов показали, что $\hat{p}=0.6$

- Джеймс Бонд различает? 

- Да! Число 0.6 больше, чем 0.5! 



## Формализация гипотезы

- Пусть $10$ экспериментов показали, что $\hat{p}=0.6$

- Джеймс Бонд различает? 

- ~~Да! Число 0.6 больше, чем 0.5!~~

- <span style="color:red"> $\hat{p}$ - случайная величина, если продолжим собирать выборку, может измениться  </span>

- Хотим узнать при текущем объёме выборки насколько $\hat{p}$ близко к $0.5$

## Доверительный интервал 

- Секундочку... Наша доля имеет асимптотически нормальное распределение

$$\hat{p} \sim N \left(p, \frac{p(1-p)}{n} \right)$$
</br>

- Доверительный интервал говорит о точности оценки


$$
P\left(\hat{p} - 2 \sqrt{\frac{\hat{p} \cdot (1 - \hat{p})}{n}} \le p \le \hat{p} + 2 \sqrt{\frac{\hat{p} \cdot (1 - \hat{p})}{n}} \right) = 0.95.
$$

</br>

> Воспользуемся этим!

## Доверительный интервал

```{r, results = 'hold'}

p_hat = 0.6
n = 10

sd_p = sqrt(p_hat*(1-p_hat)/n)
p_left  = p_hat - qnorm(1-0.05/2)*sd_p
p_right = p_hat + qnorm(1-0.05/2)*sd_p
cat('Параметр p с вероятностью 95% лежит между',p_left, 'и', p_right, '\n')
cat('Ширина интервала:', p_right - p_left)

```

</br>

- Широкий диапазон, в него попало $0.5 \Rightarrow$ Джеймс может врать 


## Мера близости 

- Если расстояние $\hat{p} - 0.5$ маленькое, Бонд не может распознавать напитки

- Что значит маленькое?


## Мера близости 

- Если расстояние $\hat{p} - 0.5$ маленькое, Бонд не может распознавать напитки

Мы знаем, что 

$$
\hat p \sim N \left(p, \frac{p(1-p)}{n} \right)
$$

</br>

Если наша гипотеза верна, то 

$$
\hat p \sim N \left(0.5, \frac{0.5(1-0.5)}{10} \right)
$$

## Мера близости 

- Значит расстояние распределено как 

$$
\hat p - 0.5 \sim N \left(0, \frac{0.5(1-0.5)}{10} \right)
$$


</br> 

- Для удобства можно перезаписать как 

$$
\frac{\hat p - 0.5}{\sqrt{\frac{0.5(1-0.5)}{10}}} \sim N (0,1)
$$
</br>

> Это и есть статистика для проверки гипотезы

## Мера близости 

- Мы выяснили как распределно "расстояние"" до значения $0.5$ при верности нулевой гипотезы 

- Осталось выбрать порог, при котором мы будем считать, что $H_0$ верна 

- Если альтернатива двусторонняя, очень большие и очень маленькие значения статистики говорят против нашей гипотезы 


## Уровень значимости 

- Если мы отвергаем $H_0$, когда она верна - мы ошибаемся 

- Фиксируем число ошибок, $\alpha$ - уровень значимости (обычно берут 1% 5% или 10%)

- Если мы упаковываем $100$ парашютов на уровне значимости $5\%$, то пять парашютистов умрут, и мы готовы с этим смириться 

- Если статистика попала в $1-\alpha$% доверительный интервал, то данные не противоречат гипотезе 


## Картинка для Бонда 

<center>
```{r, results = 'hold', fig.height=3, fig.keep='all'}
p_hat = 0.6
n = 10

sd_p = sqrt(p_hat*(1-p_hat)/n)

z_stat = (p_hat - 0.5)/sd_p   # считаем наблюдаемую статистику
z_stat_picture(z_stat, alpha = 0.05, alternative = 'two-sided')
```
</center>


## Картинка для Бонда 

<center>
```{r, results = 'hold', fig.height=3, fig.keep='all'}
p_hat = 0.6
n = 10

sd_p = sqrt(p_hat*(1-p_hat)/n)

z_stat = (p_hat - 0.5)/sd_p   # считаем наблюдаемую статистику
z_stat_picture(z_stat, alpha = 0.05, alternative = 'greater')
```
</center>


## Пояснения для картинок: 

- Голубая область - критическая область, при попадании статистики в неё - гипотеза отвергается, "расстояние"" оказывается большим

- В нашем случае наблюдаемое значение статистики попало в доверительную область 

- Гипотеза о том, что Бонд не различает между собой напитки, не отвергается для обеих альтернатив 

## Алгоритм проверки гипотез 

1. Задаём уровень значимости $\alpha$
2. Формулируем нулевую и альтернативную гипотезы.
3. Выбираем статистику для проверки гипотезы.
4. Находим наблюдаемое значение статистики по выборке.
5. Находим критические точки для выбранной статистики.
6. Сравниваем наблюдаемое значение с критическими.


## Ошибки, которые мы совершаем 

</br>

|                     | $H_0$ верна    | $H_0$ не верна |
|---------------------|----------------|----------------|
|$H_0$ не отвергается |   ok           |Ошибка $II$ рода|
|$H_0$ отвергается    |Ошибка $I$ рода |  ok            |

- Мы можем делать ошибки двух видов 

- Вероятность ошибки первого рода, $P(H_0 \text{ отвергнута} \mid H_0 \text{ верна})$, называют __уровнем значимости__ и обозначают как $\alpha$. 

- Вероятность ошибки второго рода, $P(H_0 \text{ не отвергнута} \mid H_0 \text{ не верна})$, обозначают как $\beta$. Величину $1-\beta$ называют __мощностью критерия.__ 


## Ошибки первого и второго рода

<center>
<img src="errors.jpg" height="500"> 
</center>


## Презумпция нулевой гипотезы 

- Ошибки первого и второго рода неравнозначны, ошибка первого рода критичнее (фиксируем её в начале)

- Ошибка второго рода минимизируется по остаточному принципу

> __Презумпция невиновности:__ подсудимый по умолчанию невиновен. Если нет доказательств обратному, нельзя утверждать, что он преступник, даже если он совершил преступление. 


## $P$-значение

<center>
```{r, echo=FALSE, results = 'hold', fig.height=3, fig.keep='all'}
dlimit_left  <- limitRange(dnorm, -Inf, -z_stat)
dlimit_right <- limitRange(dnorm, z_stat, Inf)

z_stat_picture(z_stat, alpha = 0.05, alternative = 'two-sided') + 
    # Делаем красную заливку
    stat_function(fun=dlimit_left, geom="area",  fill="red", alpha=0.1) +
    stat_function(fun=dlimit_right, geom="area", fill="red", alpha=0.1) +
    # Добавляем симметричкую пунктирную линию 
    geom_point(aes(x=-z_stat,y=0), color="red", size=2) +
    geom_vline(xintercept = -z_stat, size=0.3, linetype="dashed", color="red") +
    annotate("text", label=round(-z_stat,2), x= -z_stat, y=0.2, parse=T, size=4, color="darkred")

```
</center>

- Цифры $\pm 1.96$ - это критические точки, голубая площадь - это $\alpha$

- Цифры $\pm 0.65$ - это наблюдаемое значение, красная площадь - это $pvalue$ 

## Лёгкий рецепт для гипотез

<center>
```{r, echo=FALSE, results = 'hold', fig.height=3, fig.keep='all'}
dlimit_left  <- limitRange(dnorm, -Inf, -z_stat)
dlimit_right <- limitRange(dnorm, z_stat, Inf)

z_stat_picture(z_stat, alpha = 0.05, alternative = 'two-sided') + 
    # Делаем красную заливку
    stat_function(fun=dlimit_left, geom="area",  fill="red", alpha=0.1) +
    stat_function(fun=dlimit_right, geom="area", fill="red", alpha=0.1) +
    # Добавляем симметричкую пунктирную линию 
    geom_point(aes(x=-z_stat,y=0), color="red", size=2) +
    geom_vline(xintercept = -z_stat, size=0.3, linetype="dashed", color="red") +
    annotate("text", label=round(-z_stat,2), x= -z_stat, y=0.2, parse=T, size=4, color="darkred")

```
</center>

- если красная площадь больше синей, $pvalue > \alpha$, гипотеза не отвергается, статистика попала в доверительную область 

- если красная площадь меньше синей, то наблюдаемое значение в хвосте и гипотеза отвергается 

## Подсчёт $pvalue$ 

Для нормального распределения: 

<center>
```{r, results = 'hold', fig.height=3, fig.keep='all'}
z_stat
2*pnorm(-z_stat)
```
</center>

> p-значение упрощает проверку гипотез. В нашем случае оно больше уровня значимости, следовательно гипотеза не отвергается.

## Более формально про $pvalue$ 

__Достигаемый уровень значимости__ или __P-значение__ - это вероятность при справедливости нулевой гипотезы получить такое же значение статистики, как в эксперименте или ещё более экстремальное. 

</br>

$$p = P(z \ge z_{\text{набл.}} \mid H_0)$$


## Параметрические критерии 

- Обычно нас интересуют средние, доли и дисперсии

- Будем проверять гипотезы о них 

- Каждый критерий для проверки гипотезы - небольшая теорема со своими предпосылками

- Сегодня посмотрим параметрические критерии

- В гипотезах для таких критериев высказывается предположение о значении параметра распределения, из которого предположительно поступила выборка


## $Z$-статистика для доли 

Выборка: $X_1, \ldots, X_n \sim iid \hspace{2mm} Bern(p)$

</br>

Нулевая и альтернативная гипотезы: 

$$
\begin{aligned}
&H_0: \hspace{2mm} p = p_0 \\
&H_1: \hspace{2mm} p < \ne > p_0
\end{aligned}
$$
</br>

При верности нулевой гипотезы

$$
Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}} \sim N(0,1)
$$


## Задачка про присяжных

-  В 70-х годах известный педиатр и автор книг по воспитанию детей Бенджамин Спок был арестован за участие в антивоенной демонстрации. Его дело должен был рассматривать суд присяжных.

- Присяжные назначаются многоступенчатой процедурой. На последнем этапе оказалось только 90 женщин. 

- Протест адвокатов. Обвинение специально пытается сделать итоговый состав благосклонным к подсудимому, убирая женщин. 

- Был ли отбор беспристрастным? 



## Задачка про присяжных

$$
\begin{aligned}
&H_0: \hspace{2mm} p = 0.5  \hspace{2mm} \text{Отбор беспрестрастен} \\
&H_1: \hspace{2mm} p < 0.5  \hspace{2mm} \text{Женщин берут реже}
\end{aligned}
$$

<center>
```{r, results = 'hold', fig.height=3, fig.keep='all'}
n = 300
p_hat = 90/300
z_stat = (p_hat - 0.5)/sqrt(0.5*(1-0.5)/n)
p_value = pnorm(z_stat)
cat('p-value:',p_value)
z_stat_picture(z_stat, alpha = 0.05, alternative = 'less')
```
</center>


## Задачка про присяжных 

- Критическая область - левосторонняя 

- Наблюдаемое значение далеко в хвосте, гипотеза о беспристрастности отвергается 

- $pvalue$ получилось гораздо ниже $0.05$

## Проверка гипотезы в R 

```{r, results = 'hold', fig.height=3, fig.keep='all'}
test_res = prop.test(90, 300, p = 0.5, alternative = "less",
                     conf.level = 0.95, correct = FALSE)
test_res
```


```{r, results = 'hold', fig.height=3, fig.keep='all'}
test_res$p.value
test_res$estimate
```


## $Z$-статистика для доли для двух независимых выборок 

Выборки: $X_1, \ldots, X_{n_1} \sim iid \hspace{2mm} Bern(p)$ и $Y_1, \ldots, Y_{n_2} \sim iid \hspace{2mm} Bern(p)$

Нулевая и альтернативная гипотезы: 

$$
\begin{aligned}
&H_0: \hspace{2mm} p_1 = p_2 \\
&H_1: \hspace{2mm} p_1 < \ne > p_2
\end{aligned}
$$

При верности нулевой гипотезы: 

$$
\begin{aligned}
\hat{p}_1 &\sim N\left(p, \frac{p(1-p)}{n_1} \right) \\
\hat{p}_2 &\sim N\left(p, \frac{p(1-p)}{n_2} \right)
\end{aligned}
$$

## $Z$-статистика для доли для двух независимых выборок 

Статистика для проверки гипотезы: 

$$
Z = \frac{\hat p_1 - \hat p_2}{\sqrt{P(1-P)\frac{n_1 + n_2}{n_1 n_2}}} \sim N(0,1),
$$

$$P = \frac{m_1 + m_2}{n_1 + n_2} = \frac{\hat p_1 n_1 + \hat p_2 n_2}{n_1 + n_2}$$

## Рейтинг премьер-министра 

- Из 1600 опрошенных граждан Великобретании 944 высказали одобрение деятельности премьер-министра 

- Через 6 месяцев одобрение высказали 880 из 1600 опрошенных 

- Изменился ли рейтинг премьера? 

## Рейтинг премьер-министра 

</br>

$$
\begin{aligned}
&H_0: \hspace{2mm} p_1 = p_2 \hspace{2mm} \text{Рейтинг не поменялся} \\
&H_1: \hspace{2mm} p_1 \ne p_2  \hspace{2mm} \text{Рейтинг поменялся}
\end{aligned}
$$

> В качестве альтернативы будет уместна двусторонняя гипотеза, так как рейтинг мог измениться в любую сторону. 


## Рейтинг премьер-министра 

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}
n1 = 1600 
m1 = 944

n2 = 1600
m2 = 880

p1_hat = m1/n1
p2_hat = m2/n2
P = (m1 + m2)/(n1 + n2)

z_stat = (p1_hat - p2_hat)/(sqrt(P*(1-P)*(n1+n2)/(n1*n2)))

p_value = 2*pnorm(-z_stat)
cat('p-value:',p_value)
```
</center>


## Рейтинг премьер-министра 

</br>

<center>
```{r, results = 'hold', fig.height=3, fig.keep='all'}

z_stat_picture(z_stat, alpha = 0.05, alternative = 'two-sided')

```
</center>



## Рейтинг премьер-министра 

То же самое внутренними средствами R

```{r, results = 'hold', fig.height=3, fig.keep='all'}
test_res = prop.test(x = c(m1, m2), n = c(n1, n2), correct = FALSE)
test_res
```

- Протокол очень богатый! Задавайте вопросы :) 

- Какие проблемы у этого теста? 

## Рейтинг премьер-министра 

- В обоих опросах участвовали одни и те же люди, выборки связаны между собой

- Z критерий предполагает, что выборки независимы

- Нужен другой критерий 








## Рейтинг премьер-министра 

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}
n = 1600
f = 150 
g = 86

z_stat = (f - g)/(sqrt(f + g - (f-g)^2/n))

p_value = 2*pnorm(-z_stat)
cat('p-value:',p_value)
```
</center>

- гипотеза о том, что рейтинг премьера не изменился после такой очистки начинает отвергаться более уверенно


## Резюме про доли 

- Проверять гипотезы о долях помогает Z-тест 

- Он имеет асимптотически нормальное распределение 

- Статстика для связных выборок и независимых считается немного по-разному

- Обе статистики для двух долей имеют асимптотическое распределение



## Гипотезы о среднем для нормального

Выборка: $X_1, \ldots, X_n \sim iid \hspace{1mm} N(\mu, \sigma^2)$

</br>

Нулевая и альтернативная гипотезы: 

$$
\begin{aligned}
&H_0: \hspace{2mm} \mu = \mu_0 \\
&H_1: \hspace{2mm} \mu < \ne > \mu_0
\end{aligned}
$$

</br>
Статистика для проверки гипотезы: 

$$
Z = \frac{\hat \mu - \mu_0}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)
$$

## Гипотезы о среднем для нормального

Статистика с прошлого слайда работает только при известной дисперсии. Если дисперсия неизвестна, нужно оценить её и использовать статистику 

$$
t = \frac{\hat \mu - \mu_0}{\frac{s}{\sqrt{n}}} \sim t(n-1)
$$
</br> 

- Распределение у статистики точное только если выборка нормальная

## Вес детей при рождении 

- Средний вес детей при рождении 3300 г, у женщин, живущих за чертой бедности - 2800 г

- 25 женщин, живущих за чертой бедности, участвовали в экспериментальной программе ведения беременности

- Средний вес их детей составил 3075 г, стандартное отклонение 500 г

- Эффективна ли программа? 

## Вес детей при рождении 

В качестве альтернативы берём правостороннюю, так как вес детей должен был возрасти 

$$
\begin{aligned}
&H_0: \hspace{2mm} \mu = 2800  \hspace{2mm} \text{Программа не помогла}\\
&H_1: \hspace{2mm} \mu > 2800 \hspace{2mm} \text{Программа помогла}
\end{aligned}
$$

<center>
```{r, results = 'hold', fig.height=3, fig.keep='all'}
mu_0 = 2800

mu_hat = 3075
s = 500
n = 25

t_stat = sqrt(n)*(mu_hat - mu_0)/s

p_value = pt(-t_stat, df=n-1)
cat('p-value:',p_value)
```
</center>


## Вес детей при рождении 

<center>
```{r, echo=FALSE, results = 'hold', fig.height=3, fig.keep='all'}
mu_0 = 2800

mu_hat = 3075
s = 500
n = 25

t_stat = sqrt(n)*(mu_hat - mu_0)/s

t_stat_picture(t_stat, n-1, alpha = 0.05, alternative = 'greater')
```
</center>

- Наблюдаемое значение попало в критическую область, гипотеза об отсутствии эффекта от программы отвергается 


## Гипотезы о среднем в общем случае 

> Если выборка не распределена нормально, то наша оценка для среднего будет иметь асимптотически нормальное распределение. Для проверки гипотезы будет использоваться та же самая статистика, но выводы будут асимптотическми

$$
z = \frac{\hat \mu - \mu_0}{\frac{\hat \sigma}{\sqrt{n}}} \sim N(0,1)
$$



## Двухвыборочный критерий для средних

Выборки: 

$$
\begin{aligned}
& X_1, \ldots, X_{n_1} \sim iid \hspace{1mm} N(\mu_1, \sigma_1^2) \\
& Y_1, \ldots, Y_{n_2} \sim iid \hspace{1mm} N(\mu_2, \sigma_2^2)
\end{aligned}
$$

Нулевая и альтернативная гипотезы: 

$$
\begin{aligned}
&H_0: \hspace{2mm} \mu_1 = \mu_2 \\
&H_1: \hspace{2mm} \mu_1 < \ne > \mu_2
\end{aligned}
$$

Статистика для проверки гипотезы: 

$$
Z = \frac{\hat \mu_1 - \hat \mu_2}{\sqrt{ \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} }
$$


## Разные ситуации 

- Если дисперсии известны и выборки нормально распределены, то 

$$
\frac{\hat \mu_1 - \hat \mu_2}{\sqrt{ \frac{\sigma_1^2}{n_1}} + \frac{\sigma_2^2}{n_2}}\sim N(0,1)
$$

- Если дисперсии неизвестны, но равны, то 

$$ 
t = \frac{\hat \mu_1 - \hat \mu_2}{\sqrt{ \frac{s^2}{n_1} + \frac{s^2}{n_2}}} \sim t(n_1 + n_2 -2)
$$ 

Дисперсия считается по формуле: 

$$
s^2 = \frac{(n_1-1)*s_1^2 + (n_2-1)*s_2^2}{n_1 + n_2 -2}
$$


## Разные ситуации 

- Когда дисперсии неизвестные и разные, возникает проблема. Если заменить неизвестные дисперсии на оценки то 

$$
t = \frac{\hat \mu_1 - \hat \mu_2}{\sqrt{ \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} } \sim t(\nu).
$$

- Это распределение будет приближённым, точного распределения для этой статистики нет. Это называется [проблемой Беренца-Фишера.](https://ru.wikipedia.org/wiki/Нерешённые_проблемы_статистики)


## Разные ситуации


- Число степеней свободы считатся по сложной формуле 

$$
\nu = \frac{ \left(\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} \right)^2 }{ \frac{s_1^4}{n_1^2(n_1 -1)} + \frac{s_2^4}{n_2^2(n_2-1)}}
$$

- У вас в лекциях этой ситуации не было 


## Стоимость домов в Сиэтле

- имеются [данные о продажной стоимости](https://yadi.sk/i/Gn5GkSNV3Winsn) недвижимости в Сиэтле для 50 сделок в 2001 году и 50 в 2002. 

- Изменились ли в среднем цены?


## Стоимость домов в Сиэтле

$$
\begin{aligned}
&H_0: \hspace{2mm} \mu_1 = \mu_2 \hspace{2mm} \text{Стоимость не поменялась} \\
&H_1: \hspace{2mm} \mu_1 \ne \mu_2  \hspace{2mm} \text{Стоимость поменялась}
\end{aligned}
$$

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}

df = read.csv('/Users/fulyankin/Yandex.Disk.localized/R/R_prob_data/seattle.csv', sep='\t') 

# Вытащим цены в отдельные векторы
price_2002 = df[df$Year == 2002,]$Price
price_2001 = df[df$Year == 2001,]$Price

# Расчитаем всё необходимое для проверки гипотезы
n_1 = length(price_2001)
n_2 = length(price_2002)

mu_1 = mean(price_2001)
mu_2 = mean(price_2002)

s_1 = var(price_2001)
s_2 = var(price_2002)

t_stat = (mu_1 - mu_2)/sqrt(s_1/n_1 + s_2/n_2)

```
</center>



## Стоимость домов в Сиэтле

Мы не можем сказать, что дисперсии известны или равны, придётся использовать сложную статистику со сложной формулой

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}
a = (s_1/n_1 + s_2/n_2)^2
b = s_1^2/(n_1^2*(n_1-1)) + s_2^2/(n_2^2*(n_2-1))
a/b
```
</center>


Можно попробовать сначала проверить гипотезу о равенстве дисперсий


## Стоимость домов в Сиэтле

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}
t_stat_picture(t_stat, 72, alpha = 0.05, alternative = 'two-sided')

p_value = 2*pt(t_stat, df=72)
cat('p-value:',p_value)
```
</center>

гипотеза о равенстве цен не отвергается 


## Стоимость домов в Сиэтле

То же самое внутренними средствами R

```{r, results = 'hold', fig.height=3, fig.keep='all'}
t.test(price_2001, price_2002, var.equal = FALSE,
       alternative = "two.sided", conf.level = 0.95)
```

- Протокол очень богатый! Задавайте вопросы :) 

## Двухвыборочный критерий для средних (связанные выборки)

- Измерения делаются на одних и тех же объектах

- Это значит, что $\bar y - \bar x$ это то же самое, что $\overline{x-y}$

- Благодаря тому, что мы можем смотреть прирост по каждому объекту, мы скатываемся к одновыборочному критерию

## Двухвыборочный критерий для средних (связанные выборки)

$$ d_i = X_i - Y_i $$

$$ s^2 = \frac{1}{n-1}\sum_{i=1}^n (d_i - \bar d )^2$$

$$ t = \frac{\bar{d}}{s/\sqrt{n}} \sim t(n-1)$$


## Лечение детей

- 24 ребёнка прошли тест на способность к подавлению импульсивных поведенческих реакций после недели приёма метилфенидата и после недели приёма плацебо 

- Каков эффект препарата? 


## Лечение детей 

</br>

$$
\begin{aligned}
&H_0: \hspace{2mm} \mu_1 = \mu_2 \hspace{2mm} \text{Препарат неэффективен} \\
&H_1: \hspace{2mm} \mu_1 > \mu_2  \hspace{2mm} \text{Препарат хорош}
\end{aligned}
$$


## Лечение детей 

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}

df = read.csv('/Users/fulyankin/Yandex.Disk.localized/R/R_prob_data/ADHD.csv', sep=' ') 

d = df$D60 - df$D0
mu_d = mean(d)
s_d = sd(d)
n = nrow(df)

t_stat = mu_d/(s_d/sqrt(n))

p_value = 2*pt(t_stat, df=n-1)
cat('p-value:',p_value)

t_stat_picture(t_stat, n-1, alpha = 0.05, alternative = 'two-sided')

```
</center>


## Лечение детей

То же самое внутренними средствами R

```{r, results = 'hold', fig.height=3, fig.keep='all'}
t.test(df$D60, df$D0, var.equal = FALSE, paired=TRUE,
       alternative = "two.sided", conf.level = 0.95)
```

- Протокол очень богатый! Задавайте вопросы :) 


## Лечение детей

Внимание! Если не учесть, что выборки связанные, можно получить неправильный результат и сделать вывод, что лекарство не помогает детям. 

```{r, results = 'hold', fig.height=3, fig.keep='all'}
t.test(df$D0, df$D60, var.equal = FALSE,
       alternative = "two.sided", conf.level = 0.95)
```


## Резюме про средние

- Если выборка распределена нормально, можно использовать t-статистику, имеющую распределение стьюдента

- Если средних два и выборки независимы, возможны три разные ситуации

- Если выборки связанные, то всё скатывается к одновыборочному критерию

- Если выборка распределена не нормально, то используются те же статистики, но они имеют асимптотичеси нормальное распределение


## Гипотезы о дисперсии для нормального

Выборка: $X_1, \ldots, X_n \sim iid \hspace{1mm} N(\mu, \sigma^2)$

</br>

Нулевая и альтернативная гипотезы: 

$$
\begin{aligned}
&H_0: \hspace{2mm} \sigma^2 = \sigma^2_0 \\
&H_1: \hspace{2mm} \sigma^2 < \ne > \sigma^2_0
\end{aligned}
$$



## Гипотеза о дисперсии для нормального 

Статистика для проверки гипотезы при известном математическом ожидании: 

$$
F = \frac{s^2}{\sigma_0^2} = \sum_{i=1}^n \left(\frac{X_i - \mu}{\sigma_0}\right)^2 \sim \chi^2_n.
$$

Статистика для проверки гипотезы при неизвестном математическом ожидании: 

$$F = \frac{s^2}{\sigma_0^2} = \frac{(n-1) s^2}{\sigma^2} =\sum_{i=1}^n \left(\frac{X_i - \bar x}{\sigma}\right)^2 \sim \chi^2_{n-1}.$$

## Задачка 

</br>

</br>

> Задачки на этот критерий не будет. 


## Гипотеза о равенстве дисперсий для нормального 

Выборки: 

$$
\begin{aligned}
& X_1, \ldots, X_{n_1} \sim iid \hspace{1mm} N(\mu_1, \sigma_1^2) \\
& Y_1, \ldots, Y_{n_2} \sim iid \hspace{1mm} N(\mu_2, \sigma_2^2)
\end{aligned}
$$

Нулевая и альтернативная гипотезы: 

$$
\begin{aligned}
&H_0: \hspace{2mm} \sigma^2_1 = \sigma^2_2 \\
&H_1: \hspace{2mm} \sigma^2_1 < \ne > \sigma^2_2
\end{aligned}
$$
Статистика: 

$$
F = \frac{s_1^2}{s_2^2}
$$

## Гипотеза о равенстве дисперсий для нормального 

Статистика: 
$$
F = \frac{(n_1-1) \cdot s_1^2}{\sigma^2 \cdot (n_1-1)} : \frac{(n_2-1) \cdot s_2^2}{\sigma^2 \cdot(n_2-1)}.
$$
$$
F \sim \frac{\chi^2_{n_1-1}}{n_1-1} : \frac{\chi^2_{n_2-1}}{n_2-1} = F(n_1-1,n_2-1).
$$

## Вася и Анечка <3

- Вася Сидоров прыгает вдлину на соревнованиях 

- На первых была Аня Иванова (его первая любовь)

- На вторых она не была (с чего бы это...)

- Проверьте гипотезу о том, что из-за раставания Вася стал более рассеяным и точность его прыжков упала 

Нулева гипотеза: 

$$
\begin{aligned}
&H_0: \hspace{2mm} \sigma_1^2 = \sigma_2^2 \\
&H_1: \hspace{2mm} \sigma_1^2 > \sigma_2^2
\end{aligned}
$$

## Вася и Анечка <3

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}

first  = c(1.83, 1.64, 2.27, 1.78, 1.89, 2.33, 1.61, 2.31)
second = c(2.05, 1.07, 1.59, 1.96, 1.29, 1.52, 1.18, 1.47)

f_stat = var(first)/var(second)


f_crit = qf(0.05, df1 = length(first) - 1, df2 = length(second) - 1)

```
</center>

Гипотеза о том, что точность Васиных прыжков на обоих соревнованиях одинакова, не отвергается. 


## Вася и Анечка <3

<center>
```{r, results = 'hold', fig.height=2, fig.keep='all'}
var.test(first, second, alternative = 'less', conf.level = 0.95)
```
</center>


## Фишер и сигареты 

- [О том, почему Фишер не верил во вред сигарет](https://lpgenerator.ru/blog/2016/10/23/pochemu-otec-sovremennoj-statistiki-ne-veril-chto-kurenie-vyzyvaet-rak/)

<center>
<img src="fisher.png" height="500"> 
</center>



## Резюме о дисперсиях 

- Для нормальных выборок можно использовать статистики Фишера

- Для двухвыборочного критерия подойдёт F-критерий 

- Есть и другие статитсики для проверки гипотезы о дисперсиях, но мы в них углубляться не будем


## Значимость и существенность 

- Интерес представляет не величина p-значения, а размер эффекта - степень отклонения данных от нулевой гипотезы 

- На основе размера эффекта делается вывод о том, являются ли результаты практически существенными

## Значимость и несущественно 

- за три года женщины, упражнявшиеся не меньше часа в день, набрали значимо меньше веса, чем женщины, упражнявшиеся меньше 20 минут в день $(p < 0.001)$

- разница в набранном весе составила 150 г. 

- практическая значимость такого эффекта сомнительна

## Значимо и существенно 

- в 2002 году клинические испытания гормонального препарата Премарин, облегчающего симптомы менопаузы, были досрочно прерваны

- было обнаружено, что его приём ведёт к значимому увеличению риска развития рака груди на $0.08\%$, риска инсульта на $0.08\%$ и инфаркта на $0.07\%$

- формально эффект крайне мал, но с учётом численности населения он превращается в тысячи дополнительных смертей

## Незначимо, но существенно 

- лекарство, замедляющее ослабление интеллекта больных Альцгеймером

- при испытаниях выяснилось, что разница в IQ контрольной и тестовой групп составляет 13 пунктов

- разница статистически нещначима

- возможно, выборка мала для детекции эффекта и изучение лекарства стоит продолжить





