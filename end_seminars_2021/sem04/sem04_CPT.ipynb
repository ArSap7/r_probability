{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/central-limit-theorem.png\" width=\"600\"> \n",
    "\n",
    "# <center> R для тервера и матстата <br>  <br> ЗБЧ и ЦПТ в картинках </center>\n",
    "\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примерная схема матстата \n",
    "\n",
    "__Задача:__ мы предполагаем, что какая-то штука описывается каким-то распределением с параметром $\\theta$. Чтобы понимать эту штуку, нам нужно параметр $\\theta$ оценить. __Важно:__ мы препдполагаем, что $\\theta$ - константа. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/matstat_sh.png\" width=\"750\"> \n",
    "\n",
    "__Оценивание:__ получить оценку $\\hat \\theta$ можно разными методами. Например, методом моментов или методом максимального правдоподобия. \n",
    "\n",
    "__Точечная оценка:__ Та оценка, которую мы поулчим, будет функцией от выборки, то есть слуайной величиной. Если у нас есть одна выборка, то будет одна оценка. Если другая выборка, то будет другая оценка. Нам бы хотелось понимать насколько другой может оказаться оценка при новой выборке. Для этого нам нужно знать как эта оценка распределена. \n",
    "\n",
    "Зная распределение оценки, мы сможем посмотреть в каком диапазоне находится $95\\%$ её вероятностной массы и сказать, что за края этого диапазона истиное значение будет вылетать редко. Этот диапозон называется доверительным интервалом. Если он получается коротким, то оценка довольно точная. Если длинным, то не очень.\n",
    "\n",
    "__Распределение оценки:__ Чтобы построить для оценки параметра доверительный интервал, нужно знать как эта оценка распределена. Тут нам на помощь приходят разные союзники. Например, для среднего это ЦПТ. Она говорит, что среднее асимптотически нормально распределено, и мы можем использовать нормальное распределение для доверительных интервалов и проверки гипотез. Есть и другие союзники, которые помогают нам в разных ситуациях понимать насколько точными оказались прогнозы и отвечать на вопросы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что хочет статистик\n",
    "\n",
    "Когда статистик оценивает какой-нибудь параметр, он хочет: \n",
    "\n",
    "* __несмещённость__ (при фиксированном размере выборки мы в среднем не ошибаемся) \n",
    "* __состоятельность__ (при бесконечном расширении выборки мы приходим к истиному значению)\n",
    "* __эффективность__ (у нашей оценки самая маленькая дисперсия для её класса (например, для всех несмещенных оценок))\n",
    "* иногда ещё статистик ссылается на какую-то мифическую __асимптотическую нормальность__ оценки.\n",
    "\n",
    "На этом семинаре поговорим про то, что это всё значит и построим немного картинок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"ggplot2\")  # Пакет для красивых графиков \n",
    "     \n",
    "# Если вы работаете в R-studio, вы можете избежать подгрузки пакетов ниже\n",
    "# Отрегулируем размер картинок, которые будут выдаваться в нашей тетрадке\n",
    "library('repr') \n",
    "library(\"grid\")  # Пакет для субплотов\n",
    "options(repr.plot.width=4, repr.plot.height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ЗБЧ, сходимость по вероятности и состоятельность\n",
    "\n",
    "\n",
    "## Упражнение 1 (разминка) \n",
    "\n",
    "На теории вероятностей мы говорили про ЗБЧ (закон больших чисел). Мы говорили, что он очень клёвый, так как разрешает делать кучу вещей. Давайте вспомним его формулировку: \n",
    "\n",
    "#### Слабая форма ЗБЧ (Пафнутий Львович Чебышёв)\n",
    "\n",
    "Пусть $X_1, \\ldots, X_n$ попарно независимые и одинаково распределённые случайные величины с конечным вторым моментом, $E(X_i^2) < \\infty$, тогда имеет место сходимость:\n",
    "\n",
    "$$\n",
    "\\frac{X_1 + \\ldots + X_n}{n} \\overset{p}{\\to} E(X_1)\n",
    "$$\n",
    "\n",
    "__Простым языком:__ \n",
    "\n",
    "* среднее арифметическое большого числа похожих случайных величин «стабилизируется» с рочтом их числа\n",
    "* как бы сильно случайные величины не отклонялись от своего среднего значения, эти отклонения взаимно гасятся\n",
    "* если у тебя есть страховая фирма, можно заработать бабла (самая простая формулировка) \n",
    "\n",
    "> Например, в XVI веке он впервые разрешил страховым команиям зарабатывать деньги. Люди вперввые начали составлять актуарные таблицы. Это такие таблицы, где указана ожидаемая продолжительность жизни для данного возраста и пола. Люди начали собирать данные о смертности и оценивать вероятность дожития человека до определённого возраста. На этом строились тарифы на страхование. Появление подобных таблиц обязано зарождению в течение 1600-х годов теории вероятности, которая впервые объяснила людям как случайные вещи при достаточно больших масштабах сглаживаются и становятся очень даже предсказуемыми. Надо признать, что у страхования было довольно трудное детство — как раз потому, что люди плоховато понимали концепцию вероятности. В голове довольно трудно удержать её. Многие люди и по сей день ошибочно думают, что могут влиять на случайность каким-то образом. Например, некоторые думают, что чаще других выбрасывают на кубике шестёрки. А ещё многие когнитивные искажения в нашей повседневной жизни вызваны плохим пониманием вероятности. Например, многие не понимают формулу Байеса и не могут адекватно оценить вероятность того, что [они заболели.](https://dyakonov.org/2015/10/12/%D1%84%D0%BE%D1%80%D0%BC%D1%83%D0%BB%D0%B0-%D0%B1%D0%B0%D0%B9%D0%B5%D1%81%D0%B0/) Даниэль Канеман в \"Thinking fast and slow\" пишет про много таких вещей, но мы чего-то отвлеклись. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Давайте нарисуем ЗБЧ.__ Все мы знаем, что математическое ожидание игральной кости это $3.5$. Сделайте симуляцию: \n",
    "\n",
    "* подкиньте кость 1 раз, посчитайте среднее число на ней\n",
    "* подкиньте кость 2 раза, посчитайте среднее число на ней\n",
    "\n",
    ".....\n",
    "\n",
    "* подкиньте кость 500 раз, посчитайте среднее число на ней\n",
    "\n",
    "Постройте картинку для всех этих средних и убедитесь в том, что оно и правда сходится к $3.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Решаем задачку :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение 2 (сходимость по вероятности) \n",
    "\n",
    "Увидели, что оно сходится? Вопрос только в том как именно. Надо стрелкой в ЗБЧ есть какая-то буква $p$. \n",
    "\n",
    "$$\n",
    "\\frac{X_1 + \\ldots + X_n}{n} \\overset{p}{\\to} E(X_1)\n",
    "$$\n",
    "\n",
    "Она означает, что последовательность случайных величин слева сходится к случайной величине справа по вероятности, то есть чем больше $n$ тем ближе вероятность отклонения $\\bar x_n$ от $E(X)$ к нулю: \n",
    "\n",
    "$$ \n",
    "P(\\mid \\bar x_n - 3.5 \\mid \\ge \\varepsilon) \\to 0\n",
    "$$\n",
    "\n",
    "Нарисуем её! Возьмём $\\varepsilon = 0.01$, нарисуем на нашей картинке из предыдущего упражнения коридор $3.5 \\pm \\varepsilon$, продолжим ряд до $100000$ подбрасываний и увидим, как постепенно $\\bar x_n$ влезает в этот коридор и всё реже и реже выскакивает из него. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно попробовать оценить вероятность того, что последовательность из средних пробьёт на конкретном шаге установленный нами коридор. Для этого давайте сгенерируем много-много траекторий для игральной кости. Такиже как на картинке выше. А после посмотрим как часто на конкретном шаге эти траектории пробивают коридор $3.5 \\pm \\varepsilon$. Частота таких пробоин будет оценкой вероятности \n",
    "\n",
    "$$ \n",
    "P(\\mid \\bar x_n - 3.5 \\mid \\ge \\varepsilon).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Решаем задачку :)\n",
    "# На самом деле просто копируем код первой и рисуем лишнюю линию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, вероятность пробить коридор поначалу является высокой, но постепенно убывает. При этом для более узкого коридора вероятность убывает медленнее, что логично :) \n",
    "\n",
    "Для нашей ситуации со сходимостью к константе можно построить аналогичные графики для дисперсии среднего. На матстате мы её вычисляли: \n",
    "\n",
    "$$\n",
    "Var(\\bar x_n) = \\frac{Var(X_1 + \\ldots  + X_n)}{n^2} = \\frac{Var(X_1)}{n}.\n",
    "$$\n",
    "\n",
    "В знаменателе у нас $n$. По мере роста выборки разброс убывает и среднее сходится к математическому ожиданию. Разобраться в таком графике вам придётся дома. __Важно держать в голове, что дисперсия убывает только при сходимости к константе!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то как все три картинки выглядят рядом. На них нарисовано, как среднее $\\bar x$, посчитанное по выборке $x_1, \\ldots, x_n \\sim iid N(2,1),$ сходится по вероятности к $2$. \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_prob_conv.gif\" width=\"1500\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый статистик хочет состоятельности. Именно её мы сейчас илюстрировали. Узнали? Согласны? \n",
    "\n",
    "\n",
    "__Определение:__  Оценка $\\hat \\theta$ параметра $\\theta$ называется __состоятельной,__ если $\\hat \\theta \\overset{p}{\\to} \\theta$ по вероятности при росте $n$. \n",
    "\n",
    "Среднее $\\bar x_n$ это оценка для математического ожидания. Она постепенно к нему приближается, значит состоятельна. Для любой другой оценки любого другого параметра можно построить аналогичную картинку и дома вы этим займётесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение 3 (расходимость по вероятности) \n",
    "\n",
    "Теперь мы знаем как выглядит сходимость по вероятности. Интересно было бы посмотреть как выглядит её отсутствие.\n",
    "\n",
    "Распределение Коши тот ещё фрукт. У стандартного распределения Коши такая плотность: \n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\pi(1+x^2)}\n",
    "$$\n",
    "\n",
    "Выглядит красиво. Красота, при этом, приносит нам кучу проблем. Одна из таких проблем - это отсутствие математического ожидания и дисперсии. ЗБЧ говорит нам, что для некоторых распределений \n",
    "\n",
    "$$ \n",
    "P( \\mid \\bar x - E(X)\\mid \\ge \\varepsilon  ) \\to 0, \n",
    "$$\n",
    "\n",
    "то есть выборочное среднее по вероятности сходится к математическому ожиданию. Интересно было бы узнать к чему будет сходиться выборочное среднее для распределения Коши __(математического ожидания то не существует).__ \n",
    "\n",
    "Постройте для выборочного среднего распределения Коши картинку, которую мы строили при иллюстрации ЗБЧ чуть выше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Решаем задачку :) \n",
    "# На самом деле просто копируем код первой и меняем распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут может банально повести и траектория будет визуально выглядеть хорошо. Но что происходит с вероятностями? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Решаем задачку :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Никакого движения к нулю. Постоянные пробои в нашем коридоре. При этом во времени их количество никак не уменьшается. Вот так вот и выглядит отсутствие сходимости по вероятности. Обратите внимание, что величина пробоя не очень важна. В случае, когда сходимость есть, пробои также могут быть очень большими, но они происходят всё реже. Тут они не происходят реже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то как все три картинки выглядят рядом. На них изобразим первые $200$ шагов для распределения Коши. Чисто визуально сравните с первыми $200$ шагами для нормального распределения из предыдущего упражнения и ужаснитесь. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_prob_unconv.gif\" width=\"1400\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вопрос на вшивость:__  Является ли среднее состоятельной оценкой для мат ожидания распределения Коши? \n",
    "\n",
    "__Вопрос на упоротость:__ Как объяснить что такое состоятельность и зачем мы её хотим бабушке?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ЦПТ, сходимость по распределению\n",
    "\n",
    "На тервере мы говорили не только о ЗБЧ, но ещё и о ЦПТ (центральная предельная теорема). Мы говорили, что она очень клёвая, так как тоже разрешает делать кучу вещей. Вспомним её: \n",
    "\n",
    "#### ЦПТ\n",
    "\n",
    "Пусть $X_1, \\ldots, X_n$ случайные величины, имеющие одинаковое распределение с конечными математическим ожиданием и дисперсией. Обычно этот факт записывают вот так:\n",
    "\n",
    "$$\n",
    "X_1, \\ldots, X_n \\sim iid(\\mu,\\sigma^2)\n",
    "$$\n",
    "\n",
    "тогда при $n \\to \\infty$ имеет место сходимость по распределению: \n",
    "\n",
    "$$\n",
    "\\frac{X_1 + \\ldots X_n - \\mu \\cdot n}{\\sqrt{n} \\sigma } \\Rightarrow N(0,1)\n",
    "$$\n",
    "\n",
    "\n",
    "__Простым языком:__ \n",
    "\n",
    "* При определённых условиях сумма достаточно большого числа случайных величин имеет распределение близкое к нормальному \n",
    "* __Главное,__ чтобы случайные величины были похожи и не было такого, что одна резко выделяется на фоне остальных \n",
    "\n",
    "\n",
    "Нарисуем ЦПТ на картинках! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение 4 (когда там уже асимптотика)\n",
    "\n",
    "На практике ЦПТ говорит нам, что при больших значениях $n$ мы можем заменять распределение средних нормальным и не особо сильно при этом ошибаться. \n",
    "\n",
    "Возникает вопрос: __А что такое большие значения n? Когда наступает асимптотика?__ Для разных распределений  и природных явлений она наступает по-разному. Например, удивительно, сумма из равномерно-распределённых случайных величин, довольно быстро становится куполообразной. Давайте посмотрим на это.\n",
    "\n",
    "Пусть $X \\sim U[-1;1]$, пусть $Y = X_1 + \\ldots + X_n$ \n",
    "\n",
    "* Нарисуйте гистограмму для $X_1$, $X_1 + X_2$,  $X_1 + X_2 + X_3$ и $X_1 + X_2 + X_3 + X_4$.\n",
    "* На последней картинке нарисуйте плотность распределения $N(0,1)$ и визуально сравните насколько сильно оно отличается от гистограммы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже для четырёх слагаемых распределение довольно сильно напоминает $N(0,1)$. Из довольно медленно сходящихся к нормальному распределений, наверное, можно выделить логнормальное распределение. Попробуйте посмотреть на досуге на его сходимость. \n",
    "\n",
    "\n",
    "Вот так равномерное распределение будет вести себя дальше: \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_CPT_1.gif\" width=\"350\"> \n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот пример для хи-квадрат с одной степенью свободы: \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_CPT_2.gif\" width=\"350\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
